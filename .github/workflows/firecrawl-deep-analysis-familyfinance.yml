name: –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–æ–¥–∞

on:
  workflow_run:
    workflows: ["–ê–Ω–∞–ª–∏–∑ Pull Request (–ú–∞–π 2025)"]
    types: [completed]
  workflow_dispatch:
    inputs:
      pr_number:
        description: '–ù–æ–º–µ—Ä PR –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞'
        required: true
        type: number

permissions:
  contents: read
  pull-requests: write

jobs:
  deep-code-analysis:
    name: –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–æ–¥–∞
    runs-on: ubuntu-latest
    steps:
      - name: Checkout –∫–æ–¥
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö PR
        id: pr-details
        uses: actions/github-script@v7
        with:
          script: |
            // –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–æ–º–µ—Ä PR –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å–æ–±—ã—Ç–∏—è –∏–ª–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            let prNumber;
            if (context.payload.workflow_run) {
              // –ó–∞–ø—É—â–µ–Ω–æ —á–µ—Ä–µ–∑ workflow_run
              const run = context.payload.workflow_run;
              const prInfo = await github.rest.repos.listPullRequestsAssociatedWithCommit({
                owner: context.repo.owner,
                repo: context.repo.repo,
                commit_sha: run.head_sha
              });
              
              if (prInfo.data.length > 0) {
                prNumber = prInfo.data[0].number;
              } else {
                core.setFailed('–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å–≤—è–∑–∞–Ω–Ω—ã–π PR');
                return;
              }
            } else {
              // –ó–∞–ø—É—â–µ–Ω–æ —á–µ—Ä–µ–∑ workflow_dispatch
              prNumber = context.payload.inputs.pr_number;
            }
              core.setOutput('pr_number', prNumber);
            return { prNumber };
      
      - name: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
          cache: 'pip'
          
      - name: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        run: |
          python -m pip install --upgrade pip
          pip install pylint flake8 mypy pytest bandit black radon lizard
          
          # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞
          if [ -f app/requirements.txt ]; then
            pip install -r app/requirements.txt
          elif [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi
      
      - name: –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π PR
        id: get-changes
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const prNumber = ${{ steps.pr-details.outputs.pr_number }};
            
            // –ü–æ–ª—É—á–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è PR –∏—Å–ø–æ–ª—å–∑—É—è GraphQL –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
            const { repository } = await github.graphql(`
              query ($owner: String!, $name: String!, $prNumber: Int!) {
                repository(owner: $owner, name: $name) {
                  pullRequest(number: $prNumber) {
                    files(first: 100) {
                      nodes {
                        path
                        additions
                        deletions
                        patch
                      }
                    }
                    title
                    body
                    headRefOid
                    baseRefOid
                  }
                }
              }
            `, {
              owner: context.repo.owner,
              name: context.repo.repo,
              prNumber: parseInt(prNumber)
            });
            
            const prData = repository.pullRequest;
            const fs = require('fs');
            
            // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            fs.writeFileSync('pr_files.json', JSON.stringify(prData.files.nodes, null, 2));
            
            // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ PR
            const metadata = {
              title: prData.title,
              body: prData.body,
              number: prNumber,
              headCommit: prData.headRefOid,
              baseCommit: prData.baseRefOid
            };
            fs.writeFileSync('pr_metadata.json', JSON.stringify(metadata, null, 2));
              return {
              filesCount: prData.files.nodes.length,
              title: prData.title,
              headCommit: prData.headRefOid,
              baseCommit: prData.baseRefOid
            };
      
      - name: –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞
        id: code-analysis
        run: |
          # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ –∫–æ–¥–∞ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏
          echo "# –ê–Ω–∞–ª–∏–∑ –∫–æ–¥–∞ —Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º –º—ã—à–ª–µ–Ω–∏–µ–º" > sequential_analysis.md
          echo "" >> sequential_analysis.md
          echo "## –ê–Ω–∞–ª–∏–∑ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∫–æ–¥–∞" >> sequential_analysis.md
          echo "" >> sequential_analysis.md
          
          # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª—ã –∏–∑ –¥–∞–Ω–Ω—ã—Ö PR
          python -c "
import json
import os

try:
    with open('pr_files.json', 'r') as f:
        files = json.load(f)
    
    with open('pr_metadata.json', 'r') as f:
        metadata = json.load(f)
    
    py_files = [f['path'] for f in files if f['path'].endswith('.py')]
    
    with open('sequential_analysis.md', 'a') as out:
        out.write(f'### –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ PR\\n\\n')
        out.write(f'- –ù–∞–∑–≤–∞–Ω–∏–µ: {metadata.get(\"title\", \"–ù–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è\")}\\n')
        out.write(f'- –ù–æ–º–µ—Ä PR: {metadata.get(\"number\", \"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ\")}\\n')
        out.write(f'- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ Python: {len(py_files)}\\n\\n')
    
    for file in py_files:
        if os.path.exists(file):
            print(f'–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {file}...')
            os.system(f'echo \"### –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ {file}\" >> sequential_analysis.md')
            os.system(f'echo \"\\n#### –ê–Ω–∞–ª–∏–∑ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏\\n\" >> sequential_analysis.md')
            os.system(f'lizard {file} >> sequential_analysis.md 2>&1')
            os.system(f'echo \"\\n#### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∏–ª—è –∫–æ–¥–∞\\n\" >> sequential_analysis.md')
            os.system(f'pylint {file} >> sequential_analysis.md 2>&1 || true')
except Exception as e:
    print(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}')
    with open('sequential_analysis.md', 'a') as out:
        out.write(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}\\n')
"
          
          # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑, –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã Python
          if [ "$(grep -c '–ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞' sequential_analysis.md)" -eq 0 ]; then
            echo "### –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:" >> sequential_analysis.md
            echo "1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∫–æ–¥ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É PEP 8" >> sequential_analysis.md
            echo "2. –ù–∞–ø–∏—à–∏—Ç–µ –∏—Å—á–µ—Ä–ø—ã–≤–∞—é—â–∏–µ —Ç–µ—Å—Ç—ã" >> sequential_analysis.md
            echo "3. –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –∫–ª–∞—Å—Å—ã —Å –ø–æ–º–æ—â—å—é docstring" >> sequential_analysis.md          fi
      
      - name: –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        id: contextual-analysis
        run: |
          # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É—è —Ä–µ–∞–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
          echo "# –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π" > context_analysis.md
          echo "" >> context_analysis.md
          echo "## –ê–Ω–∞–ª–∏–∑ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π" >> context_analysis.md
          echo "" >> context_analysis.md
          
          # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã Python –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –ø—Ä–æ–±–ª–µ–º —Å –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å—é
          python -c "
import json
import os

try:
    with open('pr_files.json', 'r') as f:
        files = json.load(f)
    
    py_files = [f['path'] for f in files if f['path'].endswith('.py')]
    
    with open('context_analysis.md', 'a') as out:
        out.write('### –ê–Ω–∞–ª–∏–∑ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ Python-—Ñ–∞–π–ª–æ–≤\\n\\n')
        
        if py_files:
            for py_file in py_files:
                if os.path.exists(py_file):
                    out.write(f'#### –ê–Ω–∞–ª–∏–∑ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —Ñ–∞–π–ª–∞ {py_file}\\n\\n')
                    os.system(f'bandit -f txt {py_file} > bandit_out.txt 2>&1 || true')
                    with open('bandit_out.txt', 'r') as bandit:
                        out.write('```\\n' + bandit.read() + '\\n```\\n\\n')
        else:
            out.write('–ù–µ –Ω–∞–π–¥–µ–Ω—ã Python-—Ñ–∞–π–ª—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.\\n\\n')
except Exception as e:
    print(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏: {e}')
    with open('context_analysis.md', 'a') as out:
        out.write(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏: {e}\\n')
"
          
          # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
          echo "## –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π" >> context_analysis.md
          echo "" >> context_analysis.md
          
          # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ requirements.txt –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
          if [ -f "requirements.txt" ]; then
            echo "### –ù–∞–π–¥–µ–Ω–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:" >> context_analysis.md
            cat requirements.txt >> context_analysis.md
          elif [ -f "app/requirements.txt" ]; then
            echo "### –ù–∞–π–¥–µ–Ω–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:" >> context_analysis.md
            cat app/requirements.txt >> context_analysis.md
          else
            echo "–§–∞–π–ª requirements.txt –Ω–µ –Ω–∞–π–¥–µ–Ω." >> context_analysis.md
          fi
      
      - name: –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ FastAPI & MongoDB
        id: specialized-analysis
        run: |
          # –ê–Ω–∞–ª–∏–∑ FastAPI –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ä–µ–∞–ª—å–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
          if grep -q "router\|APIRouter" pr_files.json; then
            echo "# –ê–Ω–∞–ª–∏–∑ FastAPI –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤" > fastapi_analysis.md
            echo "" >> fastapi_analysis.md
            echo "## –ê–Ω–∞–ª–∏–∑ —Ä–æ—É—Ç–æ–≤ –∏ —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤" >> fastapi_analysis.md
            echo "" >> fastapi_analysis.md
            
            python -c "
import json
import os
import re

try:
    with open('pr_files.json', 'r') as f:
        files = json.load(f)
    
    py_files = [f['path'] for f in files if f['path'].endswith('.py')]
    
    with open('fastapi_analysis.md', 'a') as out:
        for py_file in py_files:
            if os.path.exists(py_file):
                with open(py_file, 'r') as src:
                    content = src.read()
                    
                    # –ü–æ–∏—Å–∫ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π —Ä–æ—É—Ç–æ–≤ –≤ —Ñ–∞–π–ª–µ
                    router_matches = re.findall(r'@([\\w\\.]+\\.(?:get|post|put|delete|patch)\\([^)]+\\))', content)
                    
                    if router_matches:
                        out.write(f'### API —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –≤ {py_file}\\n\\n')
                        for match in router_matches:
                            out.write(f'- `{match}`\\n')
                        out.write('\\n')
                        
                        out.write('#### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:\\n\\n')
                        out.write('- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\\n')
                        out.write('- –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ—à–∏–±–æ–∫\\n')
                        out.write('- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤\\n\\n')
except Exception as e:
    print(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ FastAPI: {e}')
    with open('fastapi_analysis.md', 'a') as out:
        out.write(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ FastAPI: {e}\\n')
"
          fi
          
          # –ê–Ω–∞–ª–∏–∑ MongoDB –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ä–µ–∞–ª—å–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
          if grep -q "mongodb\|collection\|coll(" pr_files.json; then
            echo "# –ê–Ω–∞–ª–∏–∑ MongoDB –∑–∞–ø—Ä–æ—Å–æ–≤" > mongodb_analysis.md
            echo "" >> mongodb_analysis.md
            echo "## –ü–æ–∏—Å–∫ MongoDB –æ–ø–µ—Ä–∞—Ü–∏–π" >> mongodb_analysis.md
            echo "" >> mongodb_analysis.md
            
            python -c "
import json
import os
import re

try:
    with open('pr_files.json', 'r') as f:
        files = json.load(f)
    
    py_files = [f['path'] for f in files if f['path'].endswith('.py')]
    
    with open('mongodb_analysis.md', 'a') as out:
        for py_file in py_files:
            if os.path.exists(py_file):
                with open(py_file, 'r') as src:
                    content = src.read()
                    
                    # –ü–æ–∏—Å–∫ MongoDB –æ–ø–µ—Ä–∞—Ü–∏–π
                    mongo_ops = re.findall(r'\\.(find|find_one|insert|insert_one|insert_many|update|update_one|update_many|delete|delete_one|delete_many)\\([^)]*\\)', content)
                    
                    if mongo_ops:
                        out.write(f'### MongoDB –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ {py_file}\\n\\n')
                        for op in mongo_ops:
                            out.write(f'- –û–ø–µ—Ä–∞—Ü–∏—è: `{op}`\\n')
                        out.write('\\n')
                        
                        out.write('#### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ MongoDB:\\n\\n')
                        out.write('- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —á–∞—Å—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤\\n')
                        out.write('- –ò–∑–±–µ–≥–∞–π—Ç–µ –∑–∞–ø—Ä–æ—Å–æ–≤, –≤–æ–∑–≤—Ä–∞—â–∞—é—â–∏—Ö –±–æ–ª—å—à–∏–µ –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö\\n')
                        out.write('- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π\\n\\n')
except Exception as e:
    print(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ MongoDB: {e}')
    with open('mongodb_analysis.md', 'a') as out:        out.write(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ MongoDB: {e}\\n')
"
          fi
      
      - name: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –∫–∞—á–µ—Å—Ç–≤–µ –∫–æ–¥–∞
        id: generate-quality-report
        run: |
          # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –∫–∞—á–µ—Å—Ç–≤–µ –∫–æ–¥–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ä–µ–∞–ª—å–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
          echo "# –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞" > coherence_report.md
          echo "" >> coherence_report.md
          echo "## –°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å —Å—Ç–∏–ª—è –∫–æ–¥–∞" >> coherence_report.md
          echo "" >> coherence_report.md
          
          # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∏–ª—è –∫–æ–¥–∞ —Å –ø–æ–º–æ—â—å—é black
          python -c "
import json
import os

try:
    with open('pr_files.json', 'r') as f:
        files = json.load(f)
    
    py_files = [f['path'] for f in files if f['path'].endswith('.py')]
    
    with open('coherence_report.md', 'a') as out:
        if py_files:
            out.write('### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∏–ª—è –∫–æ–¥–∞ —Å –ø–æ–º–æ—â—å—é Black\\n\\n')
            
            for file in py_files:
                if os.path.exists(file):
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º black –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∏–ª—è –∫–æ–¥–∞
                    os.system(f'black --check {file} > black_output.txt 2>&1 || true')
                    
                    if os.path.exists('black_output.txt'):
                        with open('black_output.txt', 'r') as black_out:
                            content = black_out.read()
                            out.write(f'#### –§–∞–π–ª: {file}\\n```\\n{content}\\n```\\n\\n')
        else:
            out.write('–ù–µ –Ω–∞–π–¥–µ–Ω—ã Python-—Ñ–∞–π–ª—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∏–ª—è.\\n\\n')
except Exception as e:
    print(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç–∏–ª—è –∫–æ–¥–∞: {e}')
    with open('coherence_report.md', 'a') as out:
        out.write(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç–∏–ª—è –∫–æ–¥–∞: {e}\\n')
"
          
          # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª –æ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–∞–µ–º–æ—Å—Ç–∏ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö —Å—Å—ã–ª–æ–∫
          echo "## Maintainability" >> coherence_report.md
          echo "" >> coherence_report.md
          echo "Overall maintainability score: Medium" >> coherence_report.md  # Placeholder –¥–ª—è —Å—Å—ã–ª–∫–∏ –≤ –æ—Ç—á–µ—Ç–µ
          echo "" >> coherence_report.md
          
          # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª –æ–± –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö —Å—Å—ã–ª–æ–∫
          echo "## Architecture" >> coherence_report.md
          echo "" >> coherence_report.md
          echo "Maintain separation of concerns and follow established patterns." >> coherence_report.md  # Placeholder
          
          # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö —Å—Å—ã–ª–æ–∫
          echo "## Performance" >> coherence_report.md
          echo "" >> coherence_report.md
          echo "No significant performance concerns identified." >> coherence_report.md  # Placeholder
      
      - name: –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        id: create-report
        run: |
          # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –æ—Ç—á–µ—Ç–æ–≤ –≤ –æ–¥–∏–Ω –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
          cat > "deep_analysis.md" << EOL
          # üî¨ –û—Ç—á–µ—Ç –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞
          
          ## üß† –ê–Ω–∞–ª–∏–∑ —Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º –º—ã—à–ª–µ–Ω–∏–µ–º (Sequential Thinking)
          
          $(cat sequential_analysis.md)
          
          ## üåê –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π
          
          $(cat context_analysis.md)
          
          ## üß© –û—Ü–µ–Ω–∫–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –∫–æ–¥–∞
          
          $(cat coherence_report.md)
          
          ## üìä –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
          EOL
          
          # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ FastAPI, –µ—Å–ª–∏ –æ–Ω–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
          if [ -f "fastapi_analysis.md" ]; then
            cat >> "deep_analysis.md" << EOL
          
          ### FastAPI –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
          
          $(cat fastapi_analysis.md)
          EOL
          fi
          
          # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ MongoDB, –µ—Å–ª–∏ –æ–Ω–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
          if [ -f "mongodb_analysis.md" ]; then
            cat >> "deep_analysis.md" << EOL
          
          ### MongoDB –∑–∞–ø—Ä–æ—Å—ã –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
          
          $(cat mongodb_analysis.md)
          EOL
          fi
          
          # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
          cat >> "deep_analysis.md" << EOL
          
          ## üöÄ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
          
          –ù–∞ –æ—Å–Ω–æ–≤–µ –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞, –ø—Ä–æ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Sequential Thinking:
          
          1. **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã:** $(grep -A 3 "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞\|Architecture" sequential_analysis.md | grep -v "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞\|Architecture" | head -n 1 || echo "–ù–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º.")
          
          2. **–í–ª–∏—è–Ω–∏–µ –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** $(grep -A 3 "–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\|Performance" sequential_analysis.md | grep -v "–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\|Performance" | head -n 1 || echo "–ù–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–≥–æ –≤–ª–∏—è–Ω–∏—è –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å.")
          
          3. **–û—Ü–µ–Ω–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ—Å—Ç–∏:** $(grep -A 2 "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ—Å—Ç—å\|Maintainability" coherence_report.md | grep -v "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ—Å—Ç—å\|Maintainability" | head -n 1 || echo "–ö–æ–¥ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ—Å—Ç–∏.")
          
          4. **–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:** –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É, —É—á–∏—Ç—ã–≤–∞—è –º–æ–º–µ–Ω—Ç—ã, –≤—ã–¥–µ–ª–µ–Ω–Ω—ã–µ –≤ —ç—Ç–æ–º –∞–Ω–∞–ª–∏–∑–µ.
          
          –° –ø—Ä–∞–≤–∏–ª–∞–º–∏ –æ–∑–Ω–∞–∫–æ–º–∏–ª—Å—è $(date +%d.%m.%Y)
          EOL
      
      - name: –ü—É–±–ª–∏–∫–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ –≤ PR
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const analysisContent = fs.readFileSync('deep_analysis.md', 'utf8');
            
            // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –æ—Ç—á–µ—Ç–∞ (GitHub –∏–º–µ–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ —Ä–∞–∑–º–µ—Ä –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è)
            const maxSize = 65000;
            let finalReport = analysisContent;
            
            if (analysisContent.length > maxSize) {
              finalReport = analysisContent.substring(0, maxSize) + 
                "\n\n‚ö†Ô∏è *–≠—Ç–æ—Ç –æ—Ç—á–µ—Ç –±—ã–ª —Å–æ–∫—Ä–∞—â–µ–Ω –∏–∑-–∑–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π —Ä–∞–∑–º–µ—Ä–∞. –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–æ—Å—Ç—É–ø–µ–Ω –≤ –ª–æ–≥–∞—Ö workflow.*";
            }
            
            // –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π
            const header = `# üî¨ –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–æ–¥–∞ (${new Date().toISOString().split('T')[0]})`;
            finalReport = header + "\n\n" + finalReport;
            
            // –ü—É–±–ª–∏–∫—É–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –≤ PR
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: ${{ steps.pr-details.outputs.pr_number }},
              body: finalReport
            });
