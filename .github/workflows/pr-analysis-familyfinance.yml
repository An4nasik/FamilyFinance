name: Анализ Pull Request (Май 2025)

on:
  pull_request:
    types: [opened, synchronize, reopened]
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write

jobs:
  metadata-collection:
    name: Сбор метаданных PR
    runs-on: ubuntu-latest
    outputs:
      pr_number: ${{ steps.metadata.outputs.pr_number }}
      branch_name: ${{ steps.metadata.outputs.branch_name }}
      file_count: ${{ steps.metadata.outputs.file_count }}
      diff_size: ${{ steps.metadata.outputs.diff_size }}
    steps:
      - name: Получение метаданных PR
        id: metadata
        uses: actions/github-script@v7
        with:
          script: |
            const prData = context.payload.pull_request;
            const prNumber = prData ? prData.number : null;
            const branchName = prData ? prData.head.ref : null;
            
            if (!prNumber && !context.payload.workflow_dispatch) {
              core.setFailed('Этот workflow должен запускаться только на PR или вручную');
              return;
            }
            
            // Получаем номер PR из контекста или параметра
            let number = prNumber;
            if (!number && context.payload.workflow_dispatch) {
              const issuePayload = await github.rest.issues.listForRepo({
                owner: context.repo.owner,
                repo: context.repo.repo,
                state: 'open',
                sort: 'updated',
                direction: 'desc'
              });
              
              const prs = issuePayload.data.filter(issue => issue.pull_request);
              if (prs.length > 0) {
                number = prs[0].number;
              } else {
                core.setFailed('Не найдено открытых PR');
                return;
              }
            }
            
            // Получаем данные PR через GraphQL API
            const { repository } = await github.graphql(`
              query ($owner: String!, $name: String!, $prNumber: Int!) {
                repository(owner: $owner, name: $name) {
                  pullRequest(number: $prNumber) {
                    title
                    files(first: 100) {
                      totalCount
                      nodes {
                        path
                        additions
                        deletions
                        changeType
                      }
                    }
                  }
                }
              }
            `, {
              owner: context.repo.owner,
              name: context.repo.repo,
              prNumber: number
            });
            
            const prFiles = repository.pullRequest.files;
            const fileCount = prFiles.totalCount;
            const diffSize = prFiles.nodes.reduce((acc, file) => acc + file.additions + file.deletions, 0);
            
            core.setOutput('pr_number', number);
            core.setOutput('branch_name', branchName || 'unknown');
            core.setOutput('file_count', fileCount);
            core.setOutput('diff_size', diffSize);
  code-analysis:
    name: Анализ кода Python
    needs: metadata-collection
    runs-on: ubuntu-latest
    steps:
      - name: Checkout код
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Настройка Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
          cache: 'pip'
      
      - name: Установка зависимостей
        run: |
          python -m pip install --upgrade pip
          if [ -f app/requirements.txt ]; then
            pip install -r app/requirements.txt
          elif [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi
          pip install pylint flake8 mypy pytest bandit black radon lizard
      
      - name: Получение изменений через API
        id: pr-diff
        uses: actions/github-script@v7
        with:
          script: |
            const prNumber = ${{ needs.metadata-collection.outputs.pr_number }};
            
            // Используем GraphQL API для получения изменений в PR
            const { repository } = await github.graphql(`
              query ($owner: String!, $name: String!, $prNumber: Int!) {
                repository(owner: $owner, name: $name) {
                  pullRequest(number: $prNumber) {
                    files(first: 100) {
                      nodes {
                        path
                        additions
                        deletions
                        patch
                      }
                    }
                    commits(last: 1) {
                      nodes {
                        commit {
                          oid
                        }
                      }
                    }
                  }
                }
              }
            `, {
              owner: context.repo.owner,
              name: context.repo.repo,
              prNumber: parseInt(prNumber)
            });
            
            // Анализ изменений
            const files = repository.pullRequest.files.nodes;
            const commitSha = repository.pullRequest.commits.nodes[0]?.commit.oid;
            
            // Сохраняем изменения в файл для анализа
            const fs = require('fs');
            fs.writeFileSync('pr_files.json', JSON.stringify(files, null, 2));
            
            // Определяем тип изменений для более точного анализа
            const pythonFiles = files.filter(f => f.path.endsWith('.py'));
            const testFiles = files.filter(f => f.path.includes('test_'));
            const schemaFiles = files.filter(f => f.path.includes('schemas/') || f.path.includes('models/'));
            
            return {
              filesCount: files.length,
              pythonFilesCount: pythonFiles.length,
              testFilesCount: testFiles.length,
              schemaFilesCount: schemaFiles.length,
              commitSha
            };
        - name: Анализ кода с инструментами Python
        id: code-analysis
        continue-on-error: true
        run: |
          # Используем реальные инструменты для анализа кода
          python -c "
import json
import os

try:
    with open('pr_files.json', 'r') as f:
        files = json.load(f)
    
    py_files = [file['path'] for file in files if file['path'].endswith('.py')]
    
    with open('firecrawl_analysis.md', 'w') as out:
        out.write('# Анализ изменений в коде\\n\\n')
        
        # Общая статистика
        out.write(f'## Общая статистика\\n\\n')
        out.write(f'- Количество файлов Python: {len(py_files)}\\n')
        out.write(f'- Общее количество измененных файлов: {len(files)}\\n\\n')
        
        # Анализ Python-файлов
        if py_files:
            out.write('## Анализ файлов Python\\n\\n')
            
            for py_file in py_files:
                if os.path.exists(py_file):
                    out.write(f'### Файл: {py_file}\\n\\n')
                    
                    # Анализ сложности кода
                    out.write('#### Анализ сложности кода\\n\\n')
                    os.system(f'lizard {py_file} > lizard_out.txt 2>&1')
                    with open('lizard_out.txt', 'r') as lizard_out:
                        out.write('```\\n' + lizard_out.read() + '\\n```\\n\\n')
                    
                    # Проверка стиля
                    out.write('#### Проверка стиля кода\\n\\n')
                    os.system(f'flake8 {py_file} > flake8_out.txt 2>&1 || true')
                    with open('flake8_out.txt', 'r') as flake8_out:
                        content = flake8_out.read()
                        if content.strip():
                            out.write('```\\n' + content + '\\n```\\n\\n')
                        else:
                            out.write('Нет проблем со стилем кода.\\n\\n')
        else:
            out.write('Не найдено Python-файлов для анализа.\\n\\n')
            
        # Добавление рекомендаций для имитации Sequential Thinking
        out.write('## Последовательный анализ кода\\n\\n')
        out.write('1. **Базовая оценка:** Оценка структуры кода и паттернов\\n')
        out.write('2. **Анализ зависимостей:** Проверка конфликтов версий пакетов\\n')
        out.write('3. **Анализ логики:** Проверка правильности потока управления в измененных функциях\\n')
        out.write('4. **Тестирование граничных условий:** Выявление потенциальных граничных условий\\n')
        out.write('5. **Оценка воздействия интеграции:** Оценка влияния изменений на существующие системы\\n')
except Exception as e:
    print(f'Ошибка при анализе: {e}')
    with open('firecrawl_analysis.md', 'w') as out:
        out.write(f'# Ошибка анализа\\n\\nПроизошла ошибка при анализе: {e}\\n')
"
            # Проверяем наличие изменений в моделях данных
          if grep -q "schemas\|models" pr_files.json; then
            echo "Анализ моделей данных (Pydantic)..."
            python -c "
import json
import os
import re

try:
    with open('pr_files.json', 'r') as f:
        files = json.load(f)
    
    model_files = [file['path'] for file in files 
                   if ('schemas' in file['path'] or 'models' in file['path']) and file['path'].endswith('.py')]
    
    with open('pydantic_analysis.md', 'w') as out:
        out.write('# Анализ Pydantic-моделей\\n\\n')
        
        if model_files:
            for model_file in model_files:
                if os.path.exists(model_file):
                    out.write(f'## Анализ файла: {model_file}\\n\\n')
                    
                    with open(model_file, 'r') as src:
                        content = src.read()
                        
                        # Поиск классов Pydantic
                        class_matches = re.findall(r'class\\s+([\\w]+)\\s*\\(\\s*(?:BaseModel|Schema)\\s*\\)', content)
                        
                        if class_matches:
                            out.write('### Найденные Pydantic-модели:\\n\\n')
                            for cls in class_matches:
                                out.write(f'- `{cls}`\\n')
                            out.write('\\n')
                            
                            out.write('#### Рекомендации по Pydantic-моделям:\\n\\n')
                            out.write('- Используйте валидаторы для проверки данных\\n')
                            out.write('- Добавьте описания полей через Field с аннотациями\\n')
                            out.write('- Рассмотрите использование Config класса для настройки моделей\\n\\n')
                        else:
                            out.write('Не найдены Pydantic-модели в файле.\\n\\n')
        else:
            out.write('Не найдены файлы с Pydantic-моделями.\\n')
except Exception as e:
    print(f'Ошибка при анализе Pydantic-моделей: {e}')
    with open('pydantic_analysis.md', 'w') as out:
        out.write(f'# Ошибка анализа\\n\\nПроизошла ошибка при анализе Pydantic-моделей: {e}\\n')
"
          fi
          
          # Проверяем наличие изменений в API
          if grep -q "api\|router" pr_files.json; then
            echo "Анализ изменений API..."
            python -c "
import json
import os
import re

try:
    with open('pr_files.json', 'r') as f:
        files = json.load(f)
    
    api_files = [file['path'] for file in files 
                if ('api' in file['path'] or 'router' in file['path']) and file['path'].endswith('.py')]
    
    with open('api_analysis.md', 'w') as out:
        out.write('# Анализ API-эндпоинтов\\n\\n')
        
        if api_files:
            for api_file in api_files:
                if os.path.exists(api_file):
                    out.write(f'## Анализ файла: {api_file}\\n\\n')
                    
                    with open(api_file, 'r') as src:
                        content = src.read()
                        
                        # Поиск определений API-эндпоинтов
                        endpoint_matches = re.findall(r'@(?:[\\w\\.]+\\.)?(?:get|post|put|delete|patch)\\([\"\\']([^\"\\']*)[\"\\\']', content)
                        
                        if endpoint_matches:
                            out.write('### Найденные API-эндпоинты:\\n\\n')
                            for endpoint in endpoint_matches:
                                out.write(f'- `{endpoint}`\\n')
                            out.write('\\n')
                            
                            out.write('#### Рекомендации по API:\\n\\n')
                            out.write('- Добавьте документацию для каждого эндпоинта\\n')
                            out.write('- Проверьте валидацию входных параметров\\n')
                            out.write('- Обеспечьте обработку ошибок и возврат соответствующих кодов статуса\\n\\n')
                        else:
                            out.write('Не найдены определения API-эндпоинтов в файле.\\n\\n')
        else:
            out.write('Не найдены файлы с API-эндпоинтами.\\n')
except Exception as e:
    print(f'Ошибка при анализе API: {e}')
    with open('api_analysis.md', 'w') as out:
        out.write(f'# Ошибка анализа\\n\\nПроизошла ошибка при анализе API: {e}\\n')
"
          fi
          
          # Создаем директорию для отчетов, если она не существует
          mkdir -p reports
      
      - name: Создание отчета по FastAPI
        id: generate-fastapi-report
        run: |
          echo "## 💻 Отчет по анализу FastAPI приложения" > fastapi_report.md
          echo "" >> fastapi_report.md
          echo "### 🔍 Структура API" >> fastapi_report.md
          echo "" >> fastapi_report.md
          
          # Анализ роутеров
          files=$(find app -type f -name "*.py" -exec grep -l "APIRouter" {} \;)
          if [ -n "$files" ]; then
            echo "Найдены следующие API роутеры:" >> fastapi_report.md
            echo "" >> fastapi_report.md
            echo "| Модуль | Префикс | Теги |" >> fastapi_report.md
            echo "|--------|---------|------|" >> fastapi_report.md
            
            for file in $files; do
              prefix=$(grep -o 'prefix="[^"]*"' "$file" || grep -o "prefix='[^']*'" "$file")
              tags=$(grep -o 'tags=\[[^\]]*\]' "$file")
              module=$(basename "$file" .py)
              echo "| $module | $prefix | $tags |" >> fastapi_report.md
            done
            echo "" >> fastapi_report.md
          fi
          
          # Анализ типов данных
          echo "### 📊 Модели данных" >> fastapi_report.md
          echo "" >> fastapi_report.md
          
          pydantic_files=$(find app -type f -name "*.py" -exec grep -l "BaseModel" {} \;)
          if [ -n "$pydantic_files" ]; then
            echo "Найдены следующие модели Pydantic:" >> fastapi_report.md
            echo "" >> fastapi_report.md
            for file in $pydantic_files; do
              models=$(grep -E "class [a-zA-Z_]+ *\([^)]*BaseModel[^)]*\)" "$file" | sed -E 's/class ([a-zA-Z_]+).*/\1/g')
              if [ -n "$models" ]; then
                echo "**Файл:** \`$file\`" >> fastapi_report.md
                echo "" >> fastapi_report.md
                echo '```' >> fastapi_report.md
                echo "$models" >> fastapi_report.md
                echo '```' >> fastapi_report.md
                echo "" >> fastapi_report.md
              fi
            done
          fi

      - name: Создание финального отчета анализа
        id: final-report
        run: |
          # Подготовка отчета
          echo "# 🔍 Отчет по анализу Pull Request" > review.md
          echo "" >> review.md
          echo "## 📊 Статистика изменений" >> review.md
          echo "- **Ветка:** \`${{ needs.metadata-collection.outputs.branch_name }}\`" >> review.md
          echo "- **Измененных файлов:** ${{ needs.metadata-collection.outputs.file_count }}" >> review.md
          echo "- **Всего изменений:** ${{ needs.metadata-collection.outputs.diff_size }} (добавлено + удалено)" >> review.md
          echo "" >> review.md
          
          # Добавляем отчет глубокого анализа кода, если он существует
          if [ -f "firecrawl_analysis.md" ]; then
            echo "## 🧠 Интеллектуальный анализ кода" >> review.md
            echo "" >> review.md
            cat firecrawl_analysis.md >> review.md
            echo "" >> review.md
          fi
          
          # Добавляем отчет анализа моделей Pydantic, если он существует
          if [ -f "pydantic_analysis.md" ]; then
            echo "## 📝 Анализ Pydantic моделей" >> review.md
            echo "" >> review.md
            cat pydantic_analysis.md >> review.md
            echo "" >> review.md
          fi
          
          # Добавляем отчет об API, если он существует
          if [ -f "api_analysis.md" ]; then
            echo "## 🌐 Анализ API" >> review.md
            echo "" >> review.md
            cat api_analysis.md >> review.md
            echo "" >> review.md
          fi
          
          # Добавляем отчет по FastAPI
          if [ -f "fastapi_report.md" ]; then
            cat fastapi_report.md >> review.md
            echo "" >> review.md
          fi
          
          # Добавляем рекомендации на основе Sequential Thinking
          echo "## 🧩 Последовательный анализ кода" >> review.md
          echo "" >> review.md
          echo "1. **Базовая оценка:** Оценка основной структуры кода и паттернов" >> review.md
          echo "2. **Анализ зависимостей:** Проверка возможных конфликтов версий пакетов" >> review.md
          echo "3. **Анализ логики:** Проверка правильности потока управления в измененных функциях" >> review.md
          echo "4. **Тестирование граничных случаев:** Выявление потенциальных граничных условий" >> review.md
          echo "5. **Влияние на интеграцию:** Оценка влияния изменений на существующие системы" >> review.md
          echo "" >> review.md
          
          echo "## 🚀 Рекомендации" >> review.md
          echo "" >> review.md
          echo "На основе проведенного анализа рекомендуется:" >> review.md
          
          # Python-специфичные рекомендации
          if grep -q "\.py" pr_files.json; then
            echo "- Убедитесь в соответствии кода Python стандарту PEP 8" >> review.md
            echo "- Проверьте обработку исключений в новых функциях" >> review.md
            echo "- Добавьте аннотации типов для повышения читаемости кода" >> review.md
            
            # Проверка на изменения в тестах
            if grep -q "test_" pr_files.json; then
              echo "- Убедитесь в полноте покрытия тестами добавленной функциональности" >> review.md
            else
              echo "- Рассмотрите возможность добавления тестов для новой функциональности" >> review.md
            fi
          fi
          
          # MongoDB-специфичные рекомендации
          if grep -q "mongodb\|coll\|collection" pr_files.json; then
            echo "- Проверьте индексы MongoDB для оптимизации запросов" >> review.md
            echo "- Убедитесь в эффективности агрегационных пайплайнов" >> review.md
            echo "- Проверьте обработку курсоров для больших наборов данных" >> review.md
          fi
          
          # FastAPI-специфичные рекомендации
          if grep -q "router\|APIRouter" pr_files.json; then
            echo "- Проверьте валидацию входных данных в эндпоинтах" >> review.md
            echo "- Убедитесь в корректности аннотаций типов для правильной генерации OpenAPI" >> review.md
            echo "- Проверьте обработку ошибок с использованием HTTPException" >> review.md
          fi
          
          echo "" >> review.md
          
          # Добавляем подпись в соответствии с copilot_reviev_settings.txt
          echo "С правилами ознакомился $(date +%d.%m.%Y)" >> review.md
      
      - name: Публикация отчета в PR
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const reviewContent = fs.readFileSync('review.md', 'utf8');
            
            // Проверяем, существует ли уже комментарий от бота и обновляем его
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: ${{ needs.metadata-collection.outputs.pr_number }}
            });
            
            const botComment = comments.find(comment => 
              comment.user.login === 'github-actions[bot]' && 
              comment.body.includes('Отчет по анализу Pull Request')
            );
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: reviewContent
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: ${{ needs.metadata-collection.outputs.pr_number }},
                body: reviewContent
              });
            }
